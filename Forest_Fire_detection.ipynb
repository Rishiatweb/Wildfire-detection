{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOkZ7g7xjpf6zvOxe0mWBm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishiatweb/Wildfire-detection/blob/main/Forest_Fire_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGI7G1td1BtB",
        "outputId": "c01f2e85-b56e-430a-c98d-518ebb531ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/abdelghaniaaba/wildfire-prediction-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.45G/1.45G [01:09<00:00, 22.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/abdelghaniaaba/wildfire-prediction-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "##direct import as similar to kaggle code\n",
        "import kagglehub\n",
        "read_only_path = kagglehub.dataset_download(\"abdelghaniaaba/wildfire-prediction-dataset\")\n",
        "print(\"Path to dataset files:\", read_only_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the source (read-only) and destination (writable) paths\n",
        "source_dir = read_only_path\n",
        "writable_dir = \"/content/wildfire_dataset_writable\"\n",
        "\n",
        "# Copy the entire directory tree\n",
        "print(f\"\\nCopying dataset from {source_dir} to {writable_dir}...\")\n",
        "if os.path.exists(writable_dir):\n",
        "    shutil.rmtree(writable_dir) # Remove if it exists to ensure a fresh copy\n",
        "shutil.copytree(source_dir, writable_dir)\n",
        "print(\"Copying complete.\")\n",
        "\n",
        "# --- IMPORTANT: Update path variables to point to the new writable directories ---\n",
        "train_dir = os.path.join(writable_dir, 'train')\n",
        "valid_dir = os.path.join(writable_dir, 'valid')\n",
        "test_dir = os.path.join(writable_dir, 'test')\n",
        "\n",
        "# Verify the new paths\n",
        "print(\"\\nUpdated paths to writable directories:\")\n",
        "print(f\"Train directory: {train_dir} (Exists: {os.path.exists(train_dir)})\")\n",
        "print(f\"Validation directory: {valid_dir} (Exists: {os.path.exists(valid_dir)})\")\n",
        "print(f\"Test directory: {test_dir} (Exists: {os.path.exists(test_dir)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN1lfkvDHHNt",
        "outputId": "d52760c2-2fd7-4d6a-e77b-6e4dcca672f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Copying dataset from /root/.cache/kagglehub/datasets/abdelghaniaaba/wildfire-prediction-dataset/versions/1 to /content/wildfire_dataset_writable...\n",
            "Copying complete.\n",
            "\n",
            "Updated paths to writable directories:\n",
            "Train directory: /content/wildfire_dataset_writable/train (Exists: True)\n",
            "Validation directory: /content/wildfire_dataset_writable/valid (Exists: True)\n",
            "Test directory: /content/wildfire_dataset_writable/test (Exists: True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def find_and_remove_tf_unreadable_images(base_dir):\n",
        "    corrupt_files = []\n",
        "    total_files = 0\n",
        "    print(f\"Scanning directory: {base_dir}\")\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            total_files += 1\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                raw_image = tf.io.read_file(file_path)\n",
        "                tf.io.decode_jpeg(raw_image)\n",
        "            except tf.errors.InvalidArgumentError as e:\n",
        "                print(f\"--> Found problematic file for TensorFlow: {file_path}\")\n",
        "                corrupt_files.append(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"--> Found other problematic file: {file_path} - Error: {e}\")\n",
        "                corrupt_files.append(file_path)\n",
        "\n",
        "    if corrupt_files:\n",
        "        print(f\"\\nFound {len(corrupt_files)} problematic files. Removing them...\")\n",
        "        for file_path in corrupt_files:\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                print(f\"Successfully removed: {file_path}\")\n",
        "            except OSError as e:\n",
        "                print(f\"Error removing file {file_path}: {e}\")\n",
        "        print(\"Removal complete.\")\n",
        "    else:\n",
        "        print(\"No problematic files found by TensorFlow decoder.\")\n",
        "    print(f\"\\nScanned {total_files} files in total in {base_dir}.\")\n",
        "\n",
        "# --- Run the cleaning process on the writable copies ---\n",
        "print(\"\\n--- Cleaning Writable Train Directory ---\")\n",
        "find_and_remove_tf_unreadable_images(train_dir)\n",
        "print(\"\\n--- Cleaning Writable Validation Directory ---\")\n",
        "find_and_remove_tf_unreadable_images(valid_dir)\n",
        "print(\"\\n--- Cleaning Writable Test Directory ---\")\n",
        "find_and_remove_tf_unreadable_images(test_dir)\n",
        "print(\"\\n\\nDataset cleaning finished. Proceeding to load data...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEtGno_GE0hF",
        "outputId": "c1795cda-2738-4ea4-9c95-4409e15bb2a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cleaning Writable Train Directory ---\n",
            "Scanning directory: /content/wildfire_dataset_writable/train\n",
            "--> Found problematic file for TensorFlow: /content/wildfire_dataset_writable/train/nowildfire/-114.152378,51.027198.jpg\n",
            "\n",
            "Found 1 problematic files. Removing them...\n",
            "Successfully removed: /content/wildfire_dataset_writable/train/nowildfire/-114.152378,51.027198.jpg\n",
            "Removal complete.\n",
            "\n",
            "Scanned 30250 files in total in /content/wildfire_dataset_writable/train.\n",
            "\n",
            "--- Cleaning Writable Validation Directory ---\n",
            "Scanning directory: /content/wildfire_dataset_writable/valid\n",
            "No problematic files found by TensorFlow decoder.\n",
            "\n",
            "Scanned 6300 files in total in /content/wildfire_dataset_writable/valid.\n",
            "\n",
            "--- Cleaning Writable Test Directory ---\n",
            "Scanning directory: /content/wildfire_dataset_writable/test\n",
            "--> Found problematic file for TensorFlow: /content/wildfire_dataset_writable/test/wildfire/-73.15884,46.38819.jpg\n",
            "\n",
            "Found 1 problematic files. Removing them...\n",
            "Successfully removed: /content/wildfire_dataset_writable/test/wildfire/-73.15884,46.38819.jpg\n",
            "Removal complete.\n",
            "\n",
            "Scanned 6300 files in total in /content/wildfire_dataset_writable/test.\n",
            "\n",
            "\n",
            "Dataset cleaning finished. Proceeding to load data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "j8-AIHEC69iQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Constants to play around with\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir, labels='inferred', label_mode='binary', image_size=IMG_SIZE,\n",
        "    interpolation='nearest', batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    valid_dir, labels='inferred', label_mode='binary', image_size=IMG_SIZE,\n",
        "    interpolation='nearest', batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_dir, labels='inferred', label_mode='binary', image_size=IMG_SIZE,\n",
        "    interpolation='nearest', batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "class_names = train_dataset.class_names\n",
        "print(\"Class Names:\", class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrq15CKKD-J-",
        "outputId": "b313320c-1343-4140-d46f-23cd14ed47ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30249 files belonging to 2 classes.\n",
            "Found 6300 files belonging to 2 classes.\n",
            "Found 6299 files belonging to 2 classes.\n",
            "Class Names: ['nowildfire', 'wildfire']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "], name=\"data_augmentation\")"
      ],
      "metadata": {
        "id": "d_OBLk0lER6l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_cnn = Sequential([\n",
        "    Input(shape=IMG_SIZE + (3,)),\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    data_augmentation,\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "], name=\"custom_cnn\")\n",
        "\n",
        "custom_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "custom_cnn.summary()\n",
        "\n",
        "print(\"\\n--- Training Custom CNN ---\")\n",
        "history_cnn = custom_cnn.fit(\n",
        "    train_dataset,\n",
        "    epochs=20,\n",
        "    validation_data=validation_dataset\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sdYFtk_NEW0X",
        "outputId": "5978f6e9-9d48-4159-9198-e53a4e6c5653"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"custom_cnn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_cnn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,169,089\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,089</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,169,089\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,089</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Custom CNN ---\n",
            "Epoch 1/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 68ms/step - accuracy: 0.8748 - loss: 0.2945 - val_accuracy: 0.9387 - val_loss: 0.1599\n",
            "Epoch 2/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 66ms/step - accuracy: 0.9311 - loss: 0.1912 - val_accuracy: 0.9205 - val_loss: 0.1966\n",
            "Epoch 3/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 78ms/step - accuracy: 0.9403 - loss: 0.1647 - val_accuracy: 0.9424 - val_loss: 0.1658\n",
            "Epoch 4/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 75ms/step - accuracy: 0.9464 - loss: 0.1519 - val_accuracy: 0.9403 - val_loss: 0.1646\n",
            "Epoch 5/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 77ms/step - accuracy: 0.9484 - loss: 0.1458 - val_accuracy: 0.9486 - val_loss: 0.1581\n",
            "Epoch 6/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 68ms/step - accuracy: 0.9492 - loss: 0.1410 - val_accuracy: 0.9600 - val_loss: 0.1156\n",
            "Epoch 7/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 70ms/step - accuracy: 0.9510 - loss: 0.1369 - val_accuracy: 0.9489 - val_loss: 0.1527\n",
            "Epoch 8/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 69ms/step - accuracy: 0.9541 - loss: 0.1328 - val_accuracy: 0.9476 - val_loss: 0.1478\n",
            "Epoch 9/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 67ms/step - accuracy: 0.9548 - loss: 0.1261 - val_accuracy: 0.9403 - val_loss: 0.2105\n",
            "Epoch 10/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 67ms/step - accuracy: 0.9551 - loss: 0.1250 - val_accuracy: 0.9502 - val_loss: 0.1616\n",
            "Epoch 11/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 67ms/step - accuracy: 0.9561 - loss: 0.1193 - val_accuracy: 0.9627 - val_loss: 0.1283\n",
            "Epoch 12/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 68ms/step - accuracy: 0.9572 - loss: 0.1197 - val_accuracy: 0.9611 - val_loss: 0.1266\n",
            "Epoch 13/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 68ms/step - accuracy: 0.9600 - loss: 0.1148 - val_accuracy: 0.9643 - val_loss: 0.1159\n",
            "Epoch 14/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 69ms/step - accuracy: 0.9619 - loss: 0.1079 - val_accuracy: 0.9586 - val_loss: 0.1512\n",
            "Epoch 15/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 67ms/step - accuracy: 0.9604 - loss: 0.1108 - val_accuracy: 0.9617 - val_loss: 0.1339\n",
            "Epoch 16/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 68ms/step - accuracy: 0.9617 - loss: 0.1040 - val_accuracy: 0.9575 - val_loss: 0.1386\n",
            "Epoch 17/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.9620 - loss: 0.1062 - val_accuracy: 0.9571 - val_loss: 0.1333\n",
            "Epoch 18/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 66ms/step - accuracy: 0.9627 - loss: 0.1047 - val_accuracy: 0.9651 - val_loss: 0.1197\n",
            "Epoch 19/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 66ms/step - accuracy: 0.9652 - loss: 0.0949 - val_accuracy: 0.9657 - val_loss: 0.1071\n",
            "Epoch 20/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 67ms/step - accuracy: 0.9672 - loss: 0.0909 - val_accuracy: 0.9667 - val_loss: 0.1105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Part A: Feature Extraction ---\n",
        "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = Input(shape=IMG_SIZE + (3,))\n",
        "x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
        "x = data_augmentation(x)\n",
        "x = base_model(x, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "transfer_model = Model(inputs, outputs)\n",
        "\n",
        "transfer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                       loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training Transfer Learning Model (Feature Extraction) ---\")\n",
        "history_transfer = transfer_model.fit(train_dataset, epochs=10, validation_data=validation_dataset)\n",
        "\n",
        "# --- Part B: Fine-Tuning ---\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "transfer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                       loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training Transfer Learning Model (Fine-Tuning) ---\")\n",
        "history_fine_tune = transfer_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=history_transfer.epoch[-1] + 10,\n",
        "    initial_epoch=history_transfer.epoch[-1],\n",
        "    validation_data=validation_dataset\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go-W6Lo_HqBT",
        "outputId": "4982c492-297a-4331-9698-b3889a515995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "\n",
            "--- Training Transfer Learning Model (Feature Extraction) ---\n",
            "Epoch 1/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 71ms/step - accuracy: 0.8826 - loss: 0.2736 - val_accuracy: 0.9448 - val_loss: 0.1489\n",
            "Epoch 2/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9367 - loss: 0.1710 - val_accuracy: 0.9486 - val_loss: 0.1410\n",
            "Epoch 3/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 69ms/step - accuracy: 0.9383 - loss: 0.1683 - val_accuracy: 0.9489 - val_loss: 0.1421\n",
            "Epoch 4/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.9375 - loss: 0.1639 - val_accuracy: 0.9481 - val_loss: 0.1404\n",
            "Epoch 5/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - accuracy: 0.9393 - loss: 0.1610 - val_accuracy: 0.9521 - val_loss: 0.1314\n",
            "Epoch 6/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 70ms/step - accuracy: 0.9389 - loss: 0.1641 - val_accuracy: 0.9460 - val_loss: 0.1450\n",
            "Epoch 7/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 69ms/step - accuracy: 0.9387 - loss: 0.1622 - val_accuracy: 0.9516 - val_loss: 0.1302\n",
            "Epoch 8/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 69ms/step - accuracy: 0.9404 - loss: 0.1578 - val_accuracy: 0.9527 - val_loss: 0.1261\n",
            "Epoch 9/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 69ms/step - accuracy: 0.9401 - loss: 0.1576 - val_accuracy: 0.9562 - val_loss: 0.1222\n",
            "Epoch 10/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9417 - loss: 0.1587 - val_accuracy: 0.9554 - val_loss: 0.1231\n",
            "\n",
            "--- Training Transfer Learning Model (Fine-Tuning) ---\n",
            "Epoch 10/19\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 114ms/step - accuracy: 0.9088 - loss: 0.2384 - val_accuracy: 0.9540 - val_loss: 0.1237\n",
            "Epoch 11/19\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 103ms/step - accuracy: 0.9360 - loss: 0.1740 - val_accuracy: 0.9597 - val_loss: 0.1119\n",
            "Epoch 12/19\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 102ms/step - accuracy: 0.9426 - loss: 0.1525 - val_accuracy: 0.9527 - val_loss: 0.1303\n",
            "Epoch 13/19\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 103ms/step - accuracy: 0.9479 - loss: 0.1361 - val_accuracy: 0.9613 - val_loss: 0.1061\n",
            "Epoch 14/19\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 103ms/step - accuracy: 0.9497 - loss: 0.1324 - val_accuracy: 0.9583 - val_loss: 0.1147\n",
            "Epoch 15/19\n",
            "\u001b[1m945/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9551 - loss: 0.1188"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model 3: Transfer Learning with ResNet50 ---\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "print(\"\\n\\n--- Setting up ResNet50 Model ---\")\n",
        "\n",
        "# --- Part A: Feature Extraction ---\n",
        "# 1. Instantiate the base model\n",
        "# Note: ResNet50 has its own preprocessing function, but for a fair comparison,\n",
        "# we'll use the same Rescaling(1./255) as the other models.\n",
        "base_model_resnet = ResNet50(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# 2. Freeze the base model\n",
        "base_model_resnet.trainable = False\n",
        "\n",
        "# 3. Create the new model by adding our layers on top\n",
        "inputs_resnet = Input(shape=IMG_SIZE + (3,))\n",
        "# Apply the same augmentation and rescaling for a fair comparison\n",
        "x_resnet = data_augmentation(inputs_resnet)\n",
        "x_resnet = tf.keras.applications.resnet.preprocess_input(x_resnet) # Use ResNet's specific preprocessing\n",
        "x_resnet = base_model_resnet(x_resnet, training=False)\n",
        "x_resnet = GlobalAveragePooling2D()(x_resnet)\n",
        "x_resnet = Dropout(0.2)(x_resnet)\n",
        "outputs_resnet = Dense(1, activation='sigmoid')(x_resnet)\n",
        "\n",
        "resnet_model = Model(inputs_resnet, outputs_resnet, name=\"resnet50_transfer_model\")\n",
        "\n",
        "# 4. Compile the model\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "resnet_model.summary()\n",
        "\n",
        "# 5. Train the model (feature extraction phase)\n",
        "print(\"\\n--- Training ResNet50 Model (Feature Extraction) ---\")\n",
        "history_resnet = resnet_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10, # Keeping epochs consistent for comparison\n",
        "    validation_data=validation_dataset,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- Part B: Fine-Tuning ---\n",
        "# 6. Unfreeze some layers of the base model\n",
        "base_model_resnet.trainable = True\n",
        "\n",
        "# Let's fine-tune a smaller portion of ResNet as it's a larger model.\n",
        "# Let's unfreeze from the last convolutional block (e.g., from layer ~143 onwards).\n",
        "for layer in base_model_resnet.layers[:143]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 7. Re-compile the model with a very low learning rate\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training ResNet50 Model (Fine-Tuning) ---\")\n",
        "# 8. Continue training\n",
        "history_fine_tune_resnet = resnet_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=history_resnet.epoch[-1] + 10, # Train for 10 more epochs\n",
        "    initial_epoch=history_resnet.epoch[-1],\n",
        "    validation_data=validation_dataset\n",
        ")"
      ],
      "metadata": {
        "id": "Ej_VPICkW9dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get true labels and predictions for both models\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0).flatten()\n",
        "y_pred_cnn_prob = custom_cnn.predict(test_dataset).flatten()\n",
        "y_pred_cnn = (y_pred_cnn_prob > 0.5).astype(int)\n",
        "y_pred_transfer_prob = transfer_model.predict(test_dataset).flatten()\n",
        "y_pred_transfer = (y_pred_transfer_prob > 0.5).astype(int)\n",
        "y_pred_resnet_prob = resnet_model.predict(test_dataset).flatten()\n",
        "y_pred_resnet = (y_pred_resnet_prob > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n--- Custom CNN Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred_cnn, target_names=class_names))\n",
        "\n",
        "print(\"\\n--- Transfer Learning Model Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred_transfer, target_names=class_names))\n",
        "\n",
        "print(\"\\n--- ResNet50 Model Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred_resnet, target_names=class_names))"
      ],
      "metadata": {
        "id": "ne7D6Yc5Gof0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Confusion Matrices\n",
        "fig, axes = plt.subplots(1, 3, figsize=(21, 6))\n",
        "# Plot Custom CNN\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_cnn, display_labels=class_names, ax=axes[0], cmap=plt.cm.Blues)\n",
        "axes[0].set_title('Custom CNN Confusion Matrix')\n",
        "# Plot MobileNetV2\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_transfer, display_labels=class_names, ax=axes[1], cmap=plt.cm.Blues)\n",
        "axes[1].set_title('MobileNetV2 Model Confusion Matrix')\n",
        "# Plot ResNet50\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_resnet, display_labels=class_names, ax=axes[2], cmap=plt.cm.Blues)\n",
        "axes[2].set_title('ResNet50 Model Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC Curves\n",
        "fpr_cnn, tpr_cnn, _ = roc_curve(y_true, y_pred_cnn_prob)\n",
        "roc_auc_cnn = auc(fpr_cnn, tpr_cnn)\n",
        "fpr_transfer, tpr_transfer, _ = roc_curve(y_true, y_pred_transfer_prob)\n",
        "roc_auc_transfer = auc(fpr_transfer, tpr_transfer)\n",
        "fpr_resnet, tpr_resnet, _ = roc_curve(y_true, y_pred_resnet_prob)\n",
        "roc_auc_resnet = auc(fpr_resnet, tpr_resnet)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_cnn, tpr_cnn, color='blue', lw=2, label=f'Custom CNN (AUC = {roc_auc_cnn:.4f})')\n",
        "plt.plot(fpr_transfer, tpr_transfer, color='yellow', lw=2, label=f'MobileNet (AUC = {roc_auc_transfer:.4f})')\n",
        "plt.plot(fpr_resnet, tpr_resnet, color='red', lw=2, label=f'ResNet50 (AUC = {roc_auc_resnet:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve Comparison', fontsize=14)\n",
        "plt.legend(loc=\"lower right\", fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gnAW5fbjHz2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}