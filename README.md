# Wildfire-detection
# A Comprehensive Analysis of Deep Learning Models for Wildfire Prediction: A Comparative Study and Data Integrity Deep Dive
Candidate: Aditya Mukhopadhyay
Date: June 13, 2025
Abstract
Wildfires pose a significant and growing global threat. This research details the development and evaluation of deep learning models for automated wildfire detection using satellite and aerial imagery. I addressed critical data integrity challenges encountered during the project, including corrupt image files and read-only file systems, detailing a systematic problem-solving approach. A comparative analysis was performed on three distinct Convolutional Neural Network (CNN) architectures: a custom-built CNN, MobileNetV2, and ResNet50. My results demonstrate the superior performance of transfer learning models, with ResNet50 achieving the highest Area Under the Receiver Operating Characteristic Curve (AUC) of 0.9987, alongside exceptional precision (7 false alarms) and robust sensitivity (152 false negatives). My findings underscore the paramount importance of data sanitation in machine learning projects and lead me to recommend the fine-tuned ResNet50 model for production-level wildfire detection systems.
Acknowledgment Regarding Submission
I sincerely apologize for the delayed submission of this report. I experienced a power cut today which significantly impacted my ability to finalize and submit the document on time. I appreciate your understanding.
1. Introduction
The escalating frequency and intensity of wildfires worldwide pose a critical threat to ecosystems, economies, and human safety. Traditional methods of wildfire detection often rely on human observation from watchtowers or patrol aircraft, which can be limited by geography, weather, and time of day. The integration of artificial intelligence, specifically deep learning, with satellite and aerial imagery offers a transformative solution, enabling automated, continuous, and wide-scale monitoring. An accurate and reliable automated system can drastically reduce detection times, facilitating a more rapid and effective response from emergency services.
This report documents a comprehensive project I undertook to develop a robust deep learning model for the classification of satellite images, with the objective of accurately distinguishing between scenes containing wildfires and those without. My analysis included a full end-to-end data science workflow, starting with model selection and data acquisition, proceeding through rigorous data cleaning and preprocessing, and culminating in the training, evaluation, and comparative analysis of multiple Convolutional Neural Network (CNN) architectures. I primarily aimed to compare a custom-built CNN against state-of-the-art pretrained models leveraging transfer learning, analyzing the trade-offs between a from-scratch implementation and an established, sophisticated architecture. The dataset used for this analysis was the "Wildfire Prediction Dataset" acquired from Kaggle.
2. Literature Review
Deep learning, particularly CNNs, has shown immense promise in various image classification tasks, including those within environmental monitoring and disaster management. The application of these advanced techniques to wildfire prediction leverages their ability to automatically learn hierarchical features from raw image data.
One prominent approach, as demonstrated by Zhang et al. (2018), involved using a customized CNN for forest fire detection from surveillance camera images. Their work highlighted the effectiveness of CNNs in accurately identifying early-stage fires, emphasizing the importance of diverse datasets for robust model performance. Similarly, another study by Muhammad et al. (2020) explored the use of pre-trained deep learning models, such as VGGNet and ResNet, for wildfire detection in real-time surveillance videos. They showcased how transfer learning significantly reduces training time and computational resources while achieving high accuracy, demonstrating the power of leveraging knowledge from large-scale image recognition tasks. Furthermore, research by Al-Smadi et al. (2021) focused on developing an IoT-based wildfire detection system incorporating CNNs for image analysis, emphasizing the integration of AI models into practical, deployable solutions for environmental monitoring. These studies collectively underscore the growing trend towards AI-driven solutions for wildfire management and the proven efficacy of CNNs and transfer learning in this domain.
3. Methodology
My methodology involved a rigorous multi-stage process, encompassing data acquisition, extensive data cleaning, model selection, and comparative evaluation of distinct deep learning architectures.
Why Google Colaboratory? I opted to use Google Colaboratory for this project primarily due to persistent pathing issues I encountered when attempting to set up these models on my local system. Given the time constraints of this project, I made the pragmatic decision to transition to Colab rather than spend valuable time debugging local environment configurations. Colab provided a readily available and consistent environment that allowed me to focus on the core data science tasks.
3.1 Data Cleaning and Preprocessing
The "Wildfire Prediction Dataset" was acquired from Kaggle using the kagglehub library. My initial attempt to train the custom CNN immediately failed with an InvalidArgumentError: jpeg::Uncompress failed during the IteratorGetNext operation. This indicated corrupted image files. My systematic approach to resolving this critical data integrity challenge was as follows:
Initial Cleaning Attempt (Pillow): My first attempt involved a Python script using the Pillow (PIL) library to open each image file. This script found no errors, yet the TensorFlow error persisted. I concluded that Pillow's flexibility allowed it to open files that TensorFlow's stricter JPEG decoder deemed invalid due to internal inconsistencies.
Advanced, Targeted Cleaning (TensorFlow): I developed a more robust cleaning script that mimicked TensorFlow's decoding process by using tf.io.read_file followed by tf.io.decode_jpeg. This method successfully identified problematic files (e.g., /kaggle/input/wildfire-prediction-dataset/train/nowildfire/-114.152378,51.027198.jpg and /kaggle/input/wildfire-prediction-dataset/test/wildfire/-73.15884,46.38819.jpg).
Overcoming Read-Only Filesystem: Attempts to delete identified corrupt files using os.remove() resulted in an [Errno 30] Read-only file system error, as kagglehub datasets are in a protected directory. To overcome this, I programmatically copied the entire dataset from the read-only source (/kaggle/input/wildfire-prediction-dataset) to a new, writable directory (/content/wildfire_dataset_writable/) within the Colab session using shutil.copytree. The TensorFlow-based cleaning script was then re-run on this writable copy, allowing successful deletion of corrupt files.
After this multi-stage data sanitation, the file paths were updated, and the data was finally prepared for reliable model training.
3.2 Model Architectures and Training
I compared three distinct CNN architectures: a custom-built CNN, MobileNetV2, and ResNet50.
Custom Convolutional Neural Network (CNN):
Architecture: My custom CNN was designed as a sequential model comprising three convolutional blocks. Each block consisted of a Conv2D layer (e.g., 32, 64, 128 filters with 3x3 kernel), followed by a MaxPooling2D layer (2x2 pool size). A Flatten layer transitioned the feature maps into a 1D vector, which was then passed through a Dense classifier head (e.g., 128 units with ReLU activation) with a Dropout layer (0.5 rate) for regularization, culminating in a final Dense output layer with sigmoid activation for binary classification. The model had approximately 11.17 million trainable parameters.
Training Details: I compiled the model using the Adam optimizer and binary cross-entropy loss. Training was conducted for 20 epochs with a batch size of 32.
MobileNetV2 (Pretrained Model):
Architecture: I utilized MobileNetV2, pretrained on the ImageNet dataset, as a base model. I loaded the model without its top (classification) layer (include_top=False) to leverage its powerful feature extraction capabilities. I then added a global average pooling layer (GlobalAveragePooling2D) to reduce feature map dimensions, followed by a Dense classifier head with a sigmoid activation for binary classification, similar to the custom CNN. The base MobileNetV2 layers were initially frozen during an initial training phase to fine-tune the new top layers, and then selectively unfrozen for a second, more granular fine-tuning phase.
Training Details: Similar compilation and training setup as the custom CNN, with a focus on fine-tuning the appended layers and then the top layers of the pretrained model.
ResNet50 (Comparative Pretrained Model):
Architecture: I also chose ResNet50, another powerful architecture pretrained on ImageNet, as a third comparative model. Similar to MobileNetV2, I loaded ResNet50 without its top layer and appended my own classification head. ResNet50's architecture, with its deep structure and revolutionary "residual connections," is known for its ability to train very deep networks effectively by mitigating the vanishing gradient problem.
Training Details: The training methodology for ResNet50 mirrored that of MobileNetV2, involving an initial phase of training only the newly added classification layers, followed by unfreezing and fine-tuning a portion of the base model's layers.
Rationale for ResNet50: My inclusion of ResNet50 in this comparative study was specifically intended to add data to my ongoing research on "Fallacies of Current Scoring Methods," allowing me to analyze how different architectural choices affect model performance across various evaluation metrics and their implications for real-world scenarios beyond just raw accuracy.
I monitored training progress and model performance metrics (accuracy, loss, and AUC) throughout the training epochs. The training curves, which I observed in my notebook, showed steady convergence for all models, indicating that the training process was stable.
4. Results
The models were evaluated on the test dataset using key classification metrics, including Accuracy, AUC, False Positives (FPs), and False Negatives (FNs).
Custom CNN Performance: The custom model achieved an AUC of 0.9942 and an overall accuracy of 98%. Its confusion matrix revealed high sensitivity (low FNs), correctly identifying a vast majority of wildfires (47 FNs). However, it had a higher rate of false alarms (105 FPs).
MobileNetV2 Performance: MobileNetV2 demonstrated the power of its pretrained features with a higher AUC of 0.9967. It was exceptionally precise (low FPs), generating only 24 false alarms. This precision, however, came at the cost of lower sensitivity, missing 249 actual wildfires (high FNs).
ResNet50 Performance: ResNet50 significantly outperformed the other two models, achieving the highest AUC of 0.9987. It combined the strengths of both, producing a virtually negligible 7 false alarms (highest precision) and significantly reducing the number of missed fires compared to MobileNetV2, with only 152 False Negatives (improved sensitivity).
Figure 1: ROC Curve Comparison of Models

Figure 1: This plot illustrates the Receiver Operating Characteristic (ROC) curves for the Custom CNN, MobileNetV2, and ResNet50 models on the test set. The curve closer to the top-left corner indicates better performance. ResNet50's curve (red) is visibly superior, demonstrating its higher AUC and better overall discriminatory power.
From these results, I observed a clear trend: transfer learning models generally outperformed the custom-built CNN. More importantly, the choice of pretrained architecture profoundly influenced the model's error profile. MobileNetV2 prioritized precision but lacked sensitivity, whereas ResNet50 provided a superior balance, showcasing its robust feature learning capabilities and the benefit of its residual connections in deep networks.
5. Conclusion
This comprehensive analysis successfully navigated significant data integrity challenges to deliver a robust comparison of three distinct deep learning architectures for wildfire detection. My findings offer clear and actionable insights.
The power of transfer learning was consistently confirmed, with both MobileNetV2 and ResNet50 outperforming my custom-built CNN in overall AUC, validating the effectiveness of leveraging pre-learned knowledge from large-scale datasets. Crucially, the study highlighted that architectural differences among pretrained models significantly impact their performance profiles; ResNet50's deep residual design proved optimally suited for this task, offering the best combination of precision and recall. Finally, the project underscored the paramount importance of thorough data sanitation. Without systematically addressing corrupt image files and file system limitations, reliable model training would have been impossible.
Limitations and Future Work: One limitation of this approach is the reliance on a specific public dataset; real-world deployment would benefit from validation on diverse geographical and environmental conditions. The models were trained for binary classification; future work could explore multi-class classification (e.g., smoke, small fire, large fire) or object detection for more granular insights. Additionally, integrating temporal data from satellite imagery to predict fire spread or assess risk dynamically would be a valuable extension.
Practical Implications: The fine-tuned ResNet50 model is the recommended solution for a production-level wildfire detection system. Its state-of-the-art accuracy, exceptionally low rate of false alarms, and strong, reliable detection rate make it the most balanced and trustworthy model among those tested. Such a system could significantly enhance the capabilities of emergency services, enabling earlier detection and more effective response strategies, thereby reducing the devastating impact of wildfires.
6. References
Al-Smadi, M., Al-Bataineh, O. A., & Al-Smadi, A. (2021). An IoT-based forest fire detection and early warning system using deep learning. Sensors, 21(2), 528.
Muhammad, K., Khan, S., & Baik, S. W. (2020). Efficient deep learning-based forest fire detection system for smart cities. IEEE Transactions on Industrial Informatics, 16(3), 1841-1849.
Zhang, H., Yu, Z., & Chen, J. (2018). Forest fire detection based on convolutional neural network. In 2018 IEEE 3rd International Conference on Cloud Computing and Big Data Analytics (ICCCBDA) (pp. 370-373). IEEE.
